{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAK84NYF4W8n",
        "outputId": "53d2373d-2811-4ee7-fd40-3b32aa611689"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9tHVQVd4rCZ"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "train_data = np.load('/content/drive/MyDrive/HW12/train_data.npy')\r\n",
        "train_label = np.load('/content/drive/MyDrive/HW12/train_label.npy')\r\n",
        "test_data = np.load('/content/drive/MyDrive/HW12/test_data.npy')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMZRPYwJspZo"
      },
      "source": [
        "# Shuffle the training data\r\n",
        "n_train = tf.shape(train_data)[0]\r\n",
        "n_test = tf.shape(test_data)[0]\r\n",
        "\r\n",
        "zip_train = list(zip(train_data, train_label))\r\n",
        "np.random.shuffle(zip_train)\r\n",
        "train_data, train_label = zip(*zip_train)\r\n",
        "\r\n",
        "train_data = tf.reshape(train_data, (5000, 28, 28, 1))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqrOh36ywNmQ",
        "outputId": "4addd739-f83b-47c0-d756-529c3d9b7d89"
      },
      "source": [
        "print(\"Number of training set: \"+ str(n_train))\r\n",
        "print(\"Number of testing set: \"+ str(n_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training set: tf.Tensor(5000, shape=(), dtype=int32)\n",
            "Number of testing set: tf.Tensor(100000, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X8EV3JqtXmS"
      },
      "source": [
        "# Define optimizers for feature extractor, classifier and domain discriminator\r\n",
        "extractor_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
        "c_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
        "d_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIBWLaMhxNga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f89bd2ce-62a2-4712-dae1-c1120bfcf84d"
      },
      "source": [
        "# Define feature extractor\r\n",
        "extractor = tf.keras.Sequential([\r\n",
        "                                 tf.keras.Input(shape=(28, 28, 1)),\r\n",
        "                                 tf.keras.layers.Conv2D(64, 3, strides=1, padding='same'),\r\n",
        "                                 tf.keras.layers.BatchNormalization(),\r\n",
        "                                 tf.keras.layers.LeakyReLU(),\r\n",
        "                                 tf.keras.layers.MaxPool2D(2, 2, padding='same'),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Conv2D(128, 3, strides=1, padding='same'),\r\n",
        "                                 tf.keras.layers.BatchNormalization(),\r\n",
        "                                 tf.keras.layers.LeakyReLU(),\r\n",
        "                                 tf.keras.layers.MaxPool2D(2, 2, padding='same'),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Conv2D(256, 3, strides=1, padding='same'),\r\n",
        "                                 tf.keras.layers.BatchNormalization(),\r\n",
        "                                 tf.keras.layers.LeakyReLU(),\r\n",
        "                                 tf.keras.layers.MaxPool2D(2, 2, padding='same'),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Conv2D(512, 3, strides=1, padding='same'),\r\n",
        "                                 tf.keras.layers.BatchNormalization(),\r\n",
        "                                 tf.keras.layers.LeakyReLU(),\r\n",
        "                                 tf.keras.layers.MaxPool2D(2, 2, padding='same'),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Flatten(),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Dense(512)\r\n",
        "                                 \r\n",
        "])\r\n",
        "x = tf.random.normal((10, 28, 28, 1))\r\n",
        "print(tf.shape(extractor(x)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 10 512], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O99edwTrzrz9"
      },
      "source": [
        "# Define domain classifier\r\n",
        "domain_classifier = tf.keras.Sequential([\r\n",
        "                                     tf.keras.Input(shape=(512, )),\r\n",
        "                                     tf.keras.layers.Dense(128, activation='relu'),\r\n",
        "                                     tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "                                     tf.keras.layers.Dense(1)\r\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wGjA4Xgz5NN"
      },
      "source": [
        "# Define label classifier\r\n",
        "label_classifier = tf.keras.Sequential([\r\n",
        "                                        tf.keras.Input(shape=(512, )),\r\n",
        "                                        tf.keras.layers.Dense(128, activation='relu'),\r\n",
        "                                        tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "                                        tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlvK83w_0kMu"
      },
      "source": [
        "# Define losses for label classifier\r\n",
        "def classifier_loss(source_label, source_label_output):\r\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy()\r\n",
        "  loss = cross_entropy(source_label, source_label_output)\r\n",
        "  return loss\r\n",
        "\r\n",
        "# Define losses for domain classifier (discriminator)\r\n",
        "def d_loss(source_domain, target_domain):\r\n",
        "  cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "  target_loss = cross_entropy(tf.ones_like(target_domain), target_domain)\r\n",
        "  source_loss = cross_entropy(tf.zeros_like(source_domain), source_domain)\r\n",
        "  return target_loss + source_loss\r\n",
        "\r\n",
        "# Define losses for feature extractor\r\n",
        "def extractor_loss(source_feature, target_feature, source_label):\r\n",
        "  source_label_output = label_classifier(source_feature)\r\n",
        "  source_label_loss = classifier_loss(source_label, source_label_output)\r\n",
        "\r\n",
        "  source_domain = domain_classifier(source_feature)\r\n",
        "  target_domain = domain_classifier(target_feature)\r\n",
        "  domain_loss = d_loss(source_domain, target_domain)\r\n",
        "\r\n",
        "  lamb = 0.1\r\n",
        "  return source_label_loss - lamb * domain_loss"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sgasiYF7cpQ",
        "outputId": "10b706a5-630a-4ba6-9558-39d34af17e29"
      },
      "source": [
        "epochs = 20\r\n",
        "\r\n",
        "for i in range(epochs):\r\n",
        "  print(\"Current epoch is:\"+str(i))\r\n",
        "  for j in range(20):\r\n",
        "    x_test = test_data[5000*i:5000*(i+1), :, :, :]\r\n",
        "    x_test = tf.reshape(x_test, (5000, 28, 28, 1))\r\n",
        "    with tf.GradientTape() as e_tape, tf.GradientTape() as d_tape, tf.GradientTape() as c_tape:\r\n",
        "      source_feature = extractor(train_data, training=True)\r\n",
        "      target_feature = extractor(x_test, training=True)\r\n",
        "\r\n",
        "      source_label = train_label\r\n",
        "      source_label_output = label_classifier(source_feature)\r\n",
        "\r\n",
        "      source_domain = domain_classifier(source_feature)\r\n",
        "      target_domain = domain_classifier(target_feature)\r\n",
        "\r\n",
        "      dd_loss = d_loss(source_domain, target_domain)\r\n",
        "      ee_loss = extractor_loss(source_feature, target_feature, source_label)\r\n",
        "      cc_loss = classifier_loss(source_label, source_label_output)\r\n",
        "\r\n",
        "    gradient_of_d = d_tape.gradient(dd_loss, domain_classifier.trainable_variables)\r\n",
        "    gradient_of_e = e_tape.gradient(ee_loss, extractor.trainable_variables)\r\n",
        "    gradient_of_c = c_tape.gradient(cc_loss, label_classifier.trainable_variables)\r\n",
        "  \r\n",
        "    extractor_optimizer.apply_gradients(zip(gradient_of_e, extractor.trainable_variables))\r\n",
        "    c_optimizer.apply_gradients(zip(gradient_of_c, label_classifier.trainable_variables))\r\n",
        "    d_optimizer.apply_gradients(zip(gradient_of_d, domain_classifier.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current epoch is:0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}