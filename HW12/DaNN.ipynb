{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAK84NYF4W8n",
        "outputId": "a6f73b2c-6a30-4934-9f58-0d427181607e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9tHVQVd4rCZ"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "train_data = np.load('/content/drive/MyDrive/HW12/train_data.npy')\r\n",
        "train_label = np.load('/content/drive/MyDrive/HW12/train_label.npy')\r\n",
        "test_data = np.load('/content/drive/MyDrive/HW12/test_data.npy')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMZRPYwJspZo"
      },
      "source": [
        "# Shuffle the training data\r\n",
        "n_train = tf.shape(train_data)[0]\r\n",
        "n_test = tf.shape(test_data)[0]\r\n",
        "\r\n",
        "zip_train = list(zip(train_data, train_label))\r\n",
        "np.random.shuffle(zip_train)\r\n",
        "train_data, train_label = zip(*zip_train)\r\n",
        "\r\n",
        "train_data = tf.reshape(train_data, (5000, 28, 28, 1))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqrOh36ywNmQ",
        "outputId": "4cf509f5-8057-4613-a818-982367da6b19"
      },
      "source": [
        "print(\"Number of training set: \"+ str(n_train))\r\n",
        "print(\"Number of testing set: \"+ str(n_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training set: tf.Tensor(5000, shape=(), dtype=int32)\n",
            "Number of testing set: tf.Tensor(100000, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X8EV3JqtXmS"
      },
      "source": [
        "# Define optimizers for feature extractor, classifier and domain discriminator\r\n",
        "extractor_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
        "c_optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
        "d_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIBWLaMhxNga"
      },
      "source": [
        "# Define feature extractor\r\n",
        "extractor = tf.keras.Sequential([\r\n",
        "                                 tf.keras.Input(shape=(28, 28, 1)),\r\n",
        "                                 tf.keras.layers.Conv2D(64, 3, strides=1, padding='same'),\r\n",
        "                                 tf.keras.layers.BatchNormalization(),\r\n",
        "                                 tf.keras.layers.LeakyReLU(),\r\n",
        "                                 tf.keras.layers.MaxPool2D(2, 2, padding='same'),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Conv2D(128, 3, strides=1, padding='same'),\r\n",
        "                                 tf.keras.layers.BatchNormalization(),\r\n",
        "                                 tf.keras.layers.LeakyReLU(),\r\n",
        "                                 tf.keras.layers.MaxPool2D(2, 2, padding='same'),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Conv2D(256, 3, strides=1, padding='same'),\r\n",
        "                                 tf.keras.layers.BatchNormalization(),\r\n",
        "                                 tf.keras.layers.LeakyReLU(),\r\n",
        "                                 tf.keras.layers.MaxPool2D(2, 2, padding='same'),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Conv2D(512, 3, strides=1, padding='same'),\r\n",
        "                                 tf.keras.layers.BatchNormalization(),\r\n",
        "                                 tf.keras.layers.LeakyReLU(),\r\n",
        "                                 tf.keras.layers.MaxPool2D(2, 2, padding='same'),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Flatten(),\r\n",
        "\r\n",
        "                                 tf.keras.layers.Dense(512)\r\n",
        "                                 \r\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O99edwTrzrz9"
      },
      "source": [
        "# Define domain classifier\r\n",
        "domain_classifier = tf.keras.Sequential([\r\n",
        "                                     tf.keras.Input(shape=(512, )),\r\n",
        "                                     tf.keras.layers.Dense(128, activation='relu'),\r\n",
        "                                     tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "                                     tf.keras.layers.Dense(1)\r\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wGjA4Xgz5NN"
      },
      "source": [
        "# Define label classifier\r\n",
        "label_classifier = tf.keras.Sequential([\r\n",
        "                                        tf.keras.Input(shape=(512, )),\r\n",
        "                                        tf.keras.layers.Dense(128, activation='relu'),\r\n",
        "                                        tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "                                        tf.keras.layers.Dense(10, activation='softmax')\r\n",
        "])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlvK83w_0kMu"
      },
      "source": [
        "# Define losses for feature extractor\r\n",
        "def extractor_loss(source_label, output_feature):\r\n",
        "  true_label = source_label[:5000, :]\r\n",
        "\r\n",
        "  source_feature = output_feature[:5000]\r\n",
        "  target_feature = output_feature[5000:]\r\n",
        "\r\n",
        "  category_cross_entropy = tf.keras.losses.CategoricalCrossentropy()\r\n",
        "  source_label_output = label_classifier(source_feature)\r\n",
        "  source_label_loss = category_cross_entropy(true_label, source_label_output)\r\n",
        "\r\n",
        "  binary_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n",
        "  domain_output = domain_classifier(output_feature)\r\n",
        "  domain_true = tf.concat((tf.zeros(5000, ), tf.ones(5000, )), axis=0)\r\n",
        "  domain_loss = binary_cross_entropy(domain_true, domain_output) \r\n",
        "\r\n",
        "  lamb = 0.1\r\n",
        "\r\n",
        "  return source_label_loss - lamb * domain_loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhUfdhSRW9tV"
      },
      "source": [
        "extractor.compile(optimizer=extractor_optimizer, loss=extractor_loss)\r\n",
        "domain_classifier.compile(optimizer=d_optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\r\n",
        "label_classifier.compile(optimizer=c_optimizer, loss=tf.keras.losses.CategoricalCrossentropy())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sgasiYF7cpQ"
      },
      "source": [
        "epochs = 50\r\n",
        "source_data = train_data\r\n",
        "source_label_for_c = tf.cast(train_label, tf.int8)\r\n",
        "source_label_for_e = tf.concat((train_label, tf.zeros_like(train_label)), axis=0)\r\n",
        "source_label_for_e = tf.cast(source_label_for_e, tf.int8)\r\n",
        "for i in range(epochs):\r\n",
        "  print(\"Current epoch is:\"+str(i))\r\n",
        "  for j in range(20):\r\n",
        "\r\n",
        "    target_data = test_data[5000*j:5000*(j+1), :, :, :]\r\n",
        "    target_data = tf.reshape(target_data, (5000, 28, 28, 1))\r\n",
        "\r\n",
        "    x = tf.concat((source_data, target_data), axis=0)\r\n",
        "    x = tf.reshape(x, (10000, 28, 28, 1))\r\n",
        "    \r\n",
        "    d_target = tf.concat((tf.zeros(5000, ), tf.ones(5000, )), axis=0)\r\n",
        "\r\n",
        "    feature_output = extractor(x, training=True)\r\n",
        "    source_feature = feature_output[:5000]\r\n",
        "    target_feature = feature_output[5000:]\r\n",
        "    # Train the domain classifier\r\n",
        "    domain_classifier.fit(feature_output, d_target, batch_size=64, epochs=5, verbose=False)\r\n",
        "\r\n",
        "    # Train the extractor and label_classifier\r\n",
        "    label_classifier.fit(source_feature, source_label_for_c, batch_size=64, epochs=1, verbose=False)\r\n",
        "    extractor.fit(x, source_label_for_e, batch_size=10000, epochs=1, shuffle=False, verbose=False)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBoF-klJqi2B"
      },
      "source": [
        "pred_source_label = label_classifier(extractor(source_data))\r\n",
        "source_error = 0\r\n",
        "for i in range(5000):\r\n",
        "  y_true = tf.where(train_label[i] == max(train_label[i]))\r\n",
        "  y_pred = tf.where(pred_source_label[i] == max(pred_source_label[i]))\r\n",
        "  \r\n",
        "  if y_true != y_pred:\r\n",
        "    source_error += 1"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1obUppLsMvy",
        "outputId": "5888a60f-4a91-4da7-eb15-4f6023e5c2e6"
      },
      "source": [
        "print(source_error)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNpXel1-ud0J",
        "outputId": "29482f1b-e7c1-4bc7-c473-74721ff6a98e"
      },
      "source": [
        "pred_target_label = label_classifier(extractor(test_data[:10]))\r\n",
        "results = []\r\n",
        "for i in range(10):\r\n",
        "  y_pred = tf.where(pred_target_label[i] == max(pred_target_label[i]))\r\n",
        "  results.append(int(y_pred.numpy()))\r\n",
        "\r\n",
        "print(results)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 2, 6, 6, 2, 4, 2, 2, 5, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}