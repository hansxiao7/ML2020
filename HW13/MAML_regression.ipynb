{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAML_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4LuzpEhIo7X"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "a_range = [0.1, 5]\r\n",
        "b_range = [0, 2*np.pi]\r\n",
        "\r\n",
        "n_task = 100\r\n",
        "\r\n",
        "a = np.random.uniform(low=a_range[0], high=a_range[1], size=n_task)\r\n",
        "b = np.random.uniform(low=b_range[0], high=b_range[1], size=n_task)\r\n",
        "\r\n",
        "x_range = [-5, 5]\r\n",
        "n_sample = 10\r\n",
        "\r\n",
        "x_data = []\r\n",
        "y_data = []\r\n",
        "for i in range(n_task):\r\n",
        "  x = np.random.uniform(low=x_range[0], high=x_range[1], size=n_sample)\r\n",
        "  y = a[i] * np.sin(x + b[i])\r\n",
        "  x = tf.reshape(x, [10, 1])\r\n",
        "  x_data.append(x)\r\n",
        "  y_data.append(y)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrUn_5cqNAqU"
      },
      "source": [
        "# Build the regression model\r\n",
        "model = tf.keras.Sequential([tf.keras.Input(shape=(1, )),\r\n",
        "                             tf.keras.layers.Dense(40, activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(40, activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "#model.build(input_shape=(None ,1)) # Initiate trainable variables\r\n",
        "\r\n",
        "model_optimizer = tf.optimizers.Adam(0.01)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7aOr_ZkRUBC"
      },
      "source": [
        "# Get training task and testing task\r\n",
        "n_train_task = 70\r\n",
        "n_test_task = 30\r\n",
        "\r\n",
        "x_train = x_data[:n_train_task]\r\n",
        "y_train = y_data[:n_train_task]\r\n",
        "\r\n",
        "x_test = x_data[n_train_task:]\r\n",
        "y_test = y_data[n_train_task:]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhpNp9lzTNUa",
        "outputId": "99fc59fa-b22e-4ad0-d4e5-d4fc7428c228"
      },
      "source": [
        "# Use first order MAML to train the model\r\n",
        "epochs = 1\r\n",
        "\r\n",
        "for i in range(epochs):\r\n",
        "  total_loss = 0\r\n",
        "  for j in range(1):#n_train_task):\r\n",
        "\r\n",
        "    # Make a deep copy for the initial variables\r\n",
        "    meta_variables = model.trainable_variables.copy()\r\n",
        "    print(meta_variables[0])\r\n",
        "  \r\n",
        "    inner_optimizer = tf.optimizers.Adam(0.1)\r\n",
        "\r\n",
        "    # Update 2 times for the model to calculate gradients\r\n",
        "    for m in range(2):\r\n",
        "      with tf.GradientTape() as tape:\r\n",
        "        y_pred = model(x_train[j])\r\n",
        "        loss = tf.keras.losses.mean_squared_error(y_train[j], y_pred)\r\n",
        "\r\n",
        "      gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "      inner_optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "    \r\n",
        "    y_pred = model(x_train[j])\r\n",
        "    total_loss += tf.reduce_mean(tf.keras.losses.mean_squared_error(y_train[j], y_pred))\r\n",
        "    # Normalize graidents\r\n",
        "    n_parameters = len(meta_variables)\r\n",
        "    for k in range(n_parameters):\r\n",
        "      # gradients[k] = tf.math.l2_normalize(gradients[k])\r\n",
        "      model.trainable_variables[k] = meta_variables[k]\r\n",
        "    print(model.trainable_variables[0])\r\n",
        "    model_optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "  if i % 10 == 0:\r\n",
        "    print('Currrent Epoch is '+str(i) + '; Total loss is ' + str(total_loss.numpy()/70))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'dense/kernel:0' shape=(1, 40) dtype=float32, numpy=\n",
            "array([[-0.20979877,  0.0758053 , -0.10078388,  0.07505153,  0.04500193,\n",
            "        -0.11527521,  0.02489735, -0.19952464, -0.01477408,  0.17647347,\n",
            "        -0.0188802 ,  0.06328756,  0.05420836, -0.18392584, -0.32840395,\n",
            "         0.06104619, -0.2380152 , -0.22383572, -0.04151263,  0.0060225 ,\n",
            "         0.0208026 , -0.09599284,  0.07783484, -0.0580711 , -0.17707594,\n",
            "         0.06436206, -0.04209348,  0.1556262 , -0.11152793, -0.07299387,\n",
            "         0.11548381,  0.02303184,  0.20319228,  0.04933336, -0.17180666,\n",
            "        -0.02472497, -0.36920878,  0.05277894, -0.09873852,  0.04455147]],\n",
            "      dtype=float32)>\n",
            "<tf.Variable 'dense/kernel:0' shape=(1, 40) dtype=float32, numpy=\n",
            "array([[-0.20979877,  0.0758053 , -0.10078388,  0.07505153,  0.04500193,\n",
            "        -0.11527521,  0.02489735, -0.19952464, -0.01477408,  0.17647347,\n",
            "        -0.0188802 ,  0.06328756,  0.05420836, -0.18392584, -0.32840395,\n",
            "         0.06104619, -0.2380152 , -0.22383572, -0.04151263,  0.0060225 ,\n",
            "         0.0208026 , -0.09599284,  0.07783484, -0.0580711 , -0.17707594,\n",
            "         0.06436206, -0.04209348,  0.1556262 , -0.11152793, -0.07299387,\n",
            "         0.11548381,  0.02303184,  0.20319228,  0.04933336, -0.17180666,\n",
            "        -0.02472497, -0.36920878,  0.05277894, -0.09873852,  0.04455147]],\n",
            "      dtype=float32)>\n",
            "Currrent Epoch is 0; Total loss is 0.07418098449707031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1MGLAOj5csm",
        "outputId": "adb289df-0171-4581-aeb8-5caf95e69414"
      },
      "source": [
        "# Calculate test error\r\n",
        "test_epoch = 1000\r\n",
        "total_test_loss = 0\r\n",
        "for j in range(n_test_task):\r\n",
        "  meta_variables = model.trainable_variables.copy()\r\n",
        "  inner_optimizer = tf.optimizers.Adam(0.01)\r\n",
        "\r\n",
        "  # Update 20 times for the model to calculate test loss\r\n",
        "  for m in range(test_epoch):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "      y_pred = model(x_test[j])\r\n",
        "      loss = tf.keras.losses.mean_squared_error(y_test[j], y_pred)\r\n",
        "\r\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "    inner_optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "  \r\n",
        "  y_pred = model(x_test[j])\r\n",
        "  total_test_loss += tf.reduce_mean(tf.keras.losses.mean_squared_error(y_test[j], y_pred))\r\n",
        "\r\n",
        "  n_parameters = len(meta_variables)\r\n",
        "  for k in range(n_parameters):\r\n",
        "    # gradients[k] = tf.math.l2_normalize(gradients[k])\r\n",
        "    model.trainable_variables[k] = meta_variables[k]\r\n",
        "\r\n",
        "print(total_test_loss/30)\r\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3.7374742, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXlNxRGY67vs",
        "outputId": "0ca167bd-4e41-4dfb-aad7-f8b503486581"
      },
      "source": [
        "# Build the regression model\r\n",
        "model_2 = tf.keras.Sequential([tf.keras.Input(shape=(1, )),\r\n",
        "                             tf.keras.layers.Dense(40, activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(40, activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "model_2_optimizer = tf.optimizers.Adam(0.01)\r\n",
        "# Calculate test error\r\n",
        "test_epoch = 1000\r\n",
        "total_test_loss = 0\r\n",
        "for j in range(n_test_task):\r\n",
        "  meta_variables = model_2.trainable_variables.copy()\r\n",
        "  inner_optimizer = tf.optimizers.Adam(0.01)\r\n",
        "\r\n",
        "  # Update 20 times for the model to calculate test loss\r\n",
        "  for m in range(test_epoch):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "      y_pred = model_2(x_test[j])\r\n",
        "      loss = tf.keras.losses.mean_squared_error(y_test[j], y_pred)\r\n",
        "\r\n",
        "    gradients = tape.gradient(loss, model_2.trainable_variables)\r\n",
        "    inner_optimizer.apply_gradients(zip(gradients, model_2.trainable_variables))\r\n",
        "  \r\n",
        "  y_pred = model_2(x_test[j])\r\n",
        "  total_test_loss += tf.reduce_mean(tf.keras.losses.mean_squared_error(y_test[j], y_pred))\r\n",
        "\r\n",
        "  n_parameters = len(meta_variables)\r\n",
        "  for k in range(n_parameters):\r\n",
        "    # gradients[k] = tf.math.l2_normalize(gradients[k])\r\n",
        "    model_2.trainable_variables[k] = meta_variables[k]\r\n",
        "\r\n",
        "print(total_test_loss/30)\r\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3.7374747, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}