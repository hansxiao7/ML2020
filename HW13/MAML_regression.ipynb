{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAML_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4LuzpEhIo7X"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "a_range = [0.1, 5]\r\n",
        "b_range = [0, 2*np.pi]\r\n",
        "\r\n",
        "n_task = 100\r\n",
        "\r\n",
        "a = np.random.uniform(low=a_range[0], high=a_range[1], size=n_task)\r\n",
        "b = np.random.uniform(low=b_range[0], high=b_range[1], size=n_task)\r\n",
        "\r\n",
        "x_range = [-5, 5]\r\n",
        "n_sample = 10\r\n",
        "\r\n",
        "x_data = []\r\n",
        "y_data = []\r\n",
        "for i in range(n_task):\r\n",
        "  x = np.random.uniform(low=x_range[0], high=x_range[1], size=n_sample)\r\n",
        "  y = a[i] * np.sin(x + b[i])\r\n",
        "  x = tf.reshape(x, [10, 1])\r\n",
        "  x_data.append(x)\r\n",
        "  y_data.append(y)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrUn_5cqNAqU"
      },
      "source": [
        "# Build the regression model\r\n",
        "model = tf.keras.Sequential([tf.keras.Input(shape=(1, )),\r\n",
        "                             tf.keras.layers.Dense(40, activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(40, activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "model_optimizer = tf.optimizers.Adam(0.01)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7aOr_ZkRUBC"
      },
      "source": [
        "# Get training task and testing task\r\n",
        "n_train_task = 70\r\n",
        "n_test_task = 30\r\n",
        "\r\n",
        "x_train = x_data[:n_train_task]\r\n",
        "y_train = y_data[:n_train_task]\r\n",
        "\r\n",
        "x_test = x_data[n_train_task:]\r\n",
        "y_test = y_data[n_train_task:]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "JhpNp9lzTNUa",
        "outputId": "4ed32162-093d-4ec8-a999-41f566481b5f"
      },
      "source": [
        "# Use first order MAML to train the model\r\n",
        "epochs = 100\r\n",
        "\r\n",
        "for i in range(epochs):\r\n",
        "  total_loss = 0\r\n",
        "  for j in range(n_train_task):\r\n",
        "\r\n",
        "    # Make a deep copy for the initial variables\r\n",
        "    meta_variables = model.trainable_variables.copy()\r\n",
        "    for k in range(len(meta_variables)):\r\n",
        "      meta_variables[k] = tf.constant(meta_variables[k])\r\n",
        "    #print(meta_variables[0])\r\n",
        "  \r\n",
        "    inner_optimizer = tf.optimizers.Adam(0.01)\r\n",
        "\r\n",
        "    # Update 2 times for the model to calculate gradients\r\n",
        "    for m in range(2):\r\n",
        "      with tf.GradientTape() as tape:\r\n",
        "        y_pred = model(x_train[j])\r\n",
        "        loss = tf.keras.losses.mean_squared_error(y_train[j], y_pred)\r\n",
        "\r\n",
        "      gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "      inner_optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "    \r\n",
        "    y_pred = model(x_train[j])\r\n",
        "    total_loss += tf.reduce_mean(tf.keras.losses.mean_squared_error(y_train[j], y_pred))\r\n",
        "    # Normalize graidents\r\n",
        "    n_parameters = len(meta_variables)\r\n",
        "    for k in range(n_parameters):\r\n",
        "      model.trainable_variables[k] = meta_variables[k] - gradients[k] * 10\r\n",
        "\r\n",
        "    #model_optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "\r\n",
        "  print('Currrent Epoch is '+str(i) + '; Total loss is ' + str(total_loss.numpy()/70))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Currrent Epoch is 0; Total loss is 4.694234793526785\n",
            "Currrent Epoch is 1; Total loss is 4.692397635323661\n",
            "Currrent Epoch is 2; Total loss is 4.692112077985491\n",
            "Currrent Epoch is 3; Total loss is 4.692111642020089\n",
            "Currrent Epoch is 4; Total loss is 4.692111642020089\n",
            "Currrent Epoch is 5; Total loss is 4.692111642020089\n",
            "Currrent Epoch is 6; Total loss is 4.692111642020089\n",
            "Currrent Epoch is 7; Total loss is 4.692111642020089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-770a8d82e9ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0minner_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \"ParameterServerStrategy and CentralStorageStrategy\")\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m       \u001b[0mapply_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_unaggregated_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    878\u001b[0m       \u001b[0mapply_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[0;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mlocal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mbeta_1_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mbeta_2_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m       \u001b[0mvalues_cast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues_cast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1MGLAOj5csm",
        "outputId": "bf12dc84-3cf4-437e-bf5e-efc16832de36"
      },
      "source": [
        "# Calculate test error\r\n",
        "test_epoch = 10\r\n",
        "total_test_loss = 0\r\n",
        "\r\n",
        "meta_variables = model.trainable_variables.copy()\r\n",
        "for k in range(len(meta_variables)):\r\n",
        "  meta_variables[k] = tf.constant(meta_variables[k])\r\n",
        "\r\n",
        "for j in range(n_test_task):\r\n",
        "  inner_optimizer = tf.optimizers.Adam(0.01)\r\n",
        "\r\n",
        "  # Update 20 times for the model to calculate test loss\r\n",
        "  for m in range(test_epoch):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "      y_pred = model(x_test[j])\r\n",
        "      loss = tf.keras.losses.mean_squared_error(y_test[j], y_pred)\r\n",
        "\r\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\r\n",
        "    inner_optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "  \r\n",
        "  y_pred = model(x_test[j])\r\n",
        "  total_test_loss += tf.reduce_mean(tf.keras.losses.mean_squared_error(y_test[j], y_pred))\r\n",
        "\r\n",
        "  n_parameters = len(meta_variables)\r\n",
        "  for k in range(n_parameters):\r\n",
        "    # gradients[k] = tf.math.l2_normalize(gradients[k])\r\n",
        "    model.trainable_variables[k] = meta_variables[k]\r\n",
        "\r\n",
        "print(total_test_loss/30)\r\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3.9517038, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXlNxRGY67vs",
        "outputId": "9628526d-7238-41e1-9eef-4f8e6a9e2027"
      },
      "source": [
        "# Build the regression model\r\n",
        "model_2 = tf.keras.Sequential([tf.keras.Input(shape=(1, )),\r\n",
        "                             tf.keras.layers.Dense(40, activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(40, activation='relu'),\r\n",
        "                             tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "model_2_optimizer = tf.optimizers.Adam(0.01)\r\n",
        "# Calculate test error\r\n",
        "test_epoch = 10\r\n",
        "total_test_loss = 0\r\n",
        "\r\n",
        "meta_variables = model_2.trainable_variables.copy()\r\n",
        "for k in range(len(meta_variables)):\r\n",
        "  meta_variables[k] = tf.constant(meta_variables[k])\r\n",
        "\r\n",
        "for j in range(n_test_task):\r\n",
        "  \r\n",
        "  inner_optimizer = tf.optimizers.Adam(0.01)\r\n",
        "\r\n",
        "  # Update 20 times for the model to calculate test loss\r\n",
        "  for m in range(test_epoch):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "      y_pred = model_2(x_test[j])\r\n",
        "      loss = tf.keras.losses.mean_squared_error(y_test[j], y_pred)\r\n",
        "\r\n",
        "    gradients = tape.gradient(loss, model_2.trainable_variables)\r\n",
        "    inner_optimizer.apply_gradients(zip(gradients, model_2.trainable_variables))\r\n",
        "  \r\n",
        "  y_pred = model_2(x_test[j])\r\n",
        "  total_test_loss += tf.reduce_mean(tf.keras.losses.mean_squared_error(y_test[j], y_pred))\r\n",
        "\r\n",
        "  n_parameters = len(meta_variables)\r\n",
        "  for k in range(n_parameters):\r\n",
        "    # gradients[k] = tf.math.l2_normalize(gradients[k])\r\n",
        "    model_2.trainable_variables[k] = meta_variables[k]\r\n",
        "\r\n",
        "print(total_test_loss/30)\r\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(3.811247, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}